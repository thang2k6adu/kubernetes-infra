# K8S Dashboard

## 1. Th√†nh ph·∫ßn c·∫•u h√¨nh

### 1.1. ClusterRole: dashboard-admin

```yaml
kind: ClusterRole
metadata:
  name: dashboard-admin
```

ClusterRole ƒë·ªãnh nghƒ©a quy·ªÅn truy c·∫≠p cho Dashboard.

#### a. Core resources (apiGroups: [""])

Quy·ªÅn v·ªõi:
- pods, pods/log
- services, namespaces
- configmaps, secrets
- pvc, events, endpoints, nodes

Verbs: ["get", "list", "watch", "create", "update", "delete"]

‚Üí Dashboard c√≥ to√†n quy·ªÅn CRUD t√†i nguy√™n core.

#### b. Workloads (apps)

(resource ƒë·ªÉ ch·∫°y v√† qu·∫£n l√Ω c√°c pod, ko ph·∫£i network, storage, config m√† l√† ƒë·ªÉ v·∫≠n h√†nh)

- deployments
- replicasets
- statefulsets
- daemonsets

Cho ph√©p Dashboard:
- T·∫°o / s·ª≠a / xo√° workload
- Xem tr·∫°ng th√°i rollout

#### c. Batch jobs (batch, l√† l√¥, ch·∫°y ki·ªÉu theo l√¥, ch·∫°y xong t·∫Øt lu√¥n)

- jobs
- cronjobs

Cho ph√©p: Qu·∫£n l√Ω Job & CronJob

#### d. Networking

```yaml
apiGroups: ["networking.k8s.io"]
resources:
  - ingresses
```

Cho ph√©p: Xem v√† ch·ªânh s·ª≠a Ingress

#### e. Metrics

```yaml
apiGroups: ["metrics.k8s.io"]
resources:
  - pods
  - nodes
verbs: ["get", "list", "watch"]
```

Cho ph√©p Dashboard hi·ªÉn th·ªã:
- CPU / Memory usage c·ªßa Pod v√† Node
- (Y√™u c·∫ßu Metrics Server ho·∫∑c Prometheus Adapter ho·∫°t ƒë·ªông)

### 1.2. ServiceAccount

```yaml
kind: ServiceAccount
name: kubernetes-dashboard-admin
namespace: kubernetes-dashboard
```

ServiceAccount d√πng ƒë·ªÉ:
- ƒêƒÉng nh·∫≠p Dashboard b·∫±ng token
- G·∫Øn quy·ªÅn RBAC

### 1.3. ClusterRoleBinding

```yaml
kind: ClusterRoleBinding
name: kubernetes-dashboard-admin
```

Li√™n k·∫øt:
- ClusterRole: dashboard-admin
- ServiceAccount: kubernetes-dashboard-admin

‚Üí ServiceAccount c√≥ to√†n quy·ªÅn ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong ClusterRole tr√™n to√†n cluster.

## 2. Kustomization

```yaml
resources:
  - recommended.yaml
  - kubernetes-dashboard-sa.yaml
  - kubernetes-dashboard-rbac.yaml
```

√ù nghƒ©a:
- `recommended.yaml` ‚Üí Deploy Kubernetes Dashboard ch√≠nh th·ª©c t·ª´ GitHub
- `kubernetes-dashboard-sa.yaml` ‚Üí T·∫°o ServiceAccount admin
- `kubernetes-dashboard-rbac.yaml` ‚Üí T·∫°o ClusterRole + Binding

Kustomize gom t·∫•t c·∫£ th√†nh m·ªôt b·ªô tri·ªÉn khai duy nh·∫•t.

## 3. Ki·ªÉm tra

```bash
kubectl -n kubernetes-dashboard get pods
```

## 4. L·∫•y token ƒëƒÉng nh·∫≠p Dashboard

```bash
kubectl -n kubernetes-dashboard create token kubernetes-dashboard-admin
```

D√°n token v√†o Dashboard Login Screen.

```bash
kubectl -n kubernetes-dashboard port-forward --address 0.0.0.0 service/kubernetes-dashboard 8443:443
```

## 5. L∆∞u √Ω b·∫£o m·∫≠t

C·∫•u h√¨nh n√†y c·∫•p quy·ªÅn r·∫•t cao:

C√≥ th·ªÉ:
- Xo√° namespace
- ƒê·ªçc secrets
- T·∫°o workload b·∫•t k·ª≥
- Xem logs to√†n cluster

Khuy·∫øn ngh·ªã:

Ch·ªâ d√πng cho:
- Dev / lab
- Cluster n·ªôi b·ªô

Production n√™n:
- T·∫°o Role theo namespace
- Kh√¥ng d√πng ClusterRole full quy·ªÅn

---

# Tri·ªÉn khai kube-prometheus-stack b·∫±ng Kustomize + Helm

## 1. kustomization.yaml

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: monitoring

resources:
  - monitoring-ns.yaml

helmCharts:
  - name: kube-prometheus-stack
    repo: https://prometheus-community.github.io/helm-charts
    version: 61.3.2
    releaseName: monitoring
    namespace: monitoring
    includeCRDs: true
    valuesFile: values.yaml
```

### Gi·∫£i th√≠ch:

- `namespace: monitoring` ‚Üí M·∫∑c ƒë·ªãnh t·∫•t c·∫£ resource ƒë∆∞·ª£c deploy v√†o namespace monitoring.
- `resources: monitoring-ns.yaml` ‚Üí Khai b√°o manifest t·∫°o namespace tr∆∞·ªõc khi c√†i chart.
- `helmCharts:` D√πng Helm chart kube-prometheus-stack th√¥ng qua Kustomize:
  - `version: 61.3.2`: phi√™n b·∫£n chart
  - `includeCRDs: true`: c√†i CRDs c·ªßa Prometheus Operator
  - `valuesFile: values.yaml`: file c·∫•u h√¨nh t√πy ch·ªânh

## 2. monitoring-ns.yaml

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
```

Ch·ª©c nƒÉng:
- T·∫°o namespace monitoring ƒë·ªÉ ch·ª©a to√†n b·ªô stack monitoring.
- D√πng nh√£n `name: monitoring` ƒë·ªÉ d·ªÖ qu·∫£n l√Ω v√† filter.

## 3. values.yaml

### 3.1. T·∫Øt c√°c th√†nh ph·∫ßn kh√¥ng d√πng

```yaml
grafana:
  enabled: false

alertmanager:
  enabled: false

defaultRules:
  create: false
```

Gi·∫£i th√≠ch:
- T·∫Øt Grafana ‚Üí kh√¥ng tri·ªÉn khai UI Grafana.
- T·∫Øt Alertmanager ‚Üí kh√¥ng g·ª≠i alert.
- T·∫Øt default alert rules ‚Üí tr√°nh t·∫°o h√†ng trƒÉm rule m·∫∑c ƒë·ªãnh, ti·∫øt ki·ªám RAM/CPU.

### 3.2. B·∫≠t c√°c exporter c·∫ßn thi·∫øt

```yaml
nodeExporter:
  enabled: true

kubeStateMetrics:
  enabled: true

prometheusOperator:
  enabled: true
```

Gi·∫£i th√≠ch:
- `nodeExporter`: thu th·∫≠p metrics c·ªßa node (CPU, RAM, disk, network).
- `kubeStateMetrics`: thu th·∫≠p metrics tr·∫°ng th√°i Kubernetes object (pod, deployment, service, ‚Ä¶).
- `prometheusOperator`: controller qu·∫£n l√Ω Prometheus CRD.

### 3.3. C·∫•u h√¨nh Prometheus

```yaml
prometheus:
  enabled: true
  prometheusSpec:
    retention: 6h
```

Gi·∫£i th√≠ch:
- B·∫≠t Prometheus server.
- `retention: 6h` ‚Üí ch·ªâ l∆∞u metrics trong 6 gi·ªù (gi·∫£m dung l∆∞·ª£ng storage).

### 3.4. Resource limits

```yaml
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 300m
        memory: 512Mi
```

Gi·∫£i th√≠ch:

Gi·ªõi h·∫°n t√†i nguy√™n cho Prometheus:
- Request: CPU 100m, RAM 256Mi
- Limit: CPU 300m, RAM 512Mi

‚Üí ph√π h·ª£p cluster nh·ªè, tr√°nh Prometheus chi·∫øm h·∫øt t√†i nguy√™n node.

### 3.5. Storage

```yaml
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 1Gi
```

Gi·∫£i th√≠ch:
- T·∫°o PersistentVolumeClaim cho Prometheus
- Dung l∆∞·ª£ng: 1Gi
- Ki·ªÉu truy c·∫≠p: ReadWriteOnce

‚Üí l∆∞u d·ªØ li·ªáu metrics tr√™n disk thay v√¨ memory.

## 4. C√°ch tri·ªÉn khai

Ch·∫°y l·ªánh:

```bash
kustomize build --enable-helm . | kubectl apply -f -
```

Ho·∫∑c v·ªõi ArgoCD (GitOps):
- Khai b√°o Application tr·ªè t·ªõi th∆∞ m·ª•c ch·ª©a kustomization.yaml
- ArgoCD s·∫Ω render Helm chart v√† apply v√†o cluster.

## 5. Nh·ªØng ƒëi·ªÉm c·∫ßn l∆∞u √Ω

**Kh√¥ng c√≥ Grafana:**

Mu·ªën xem metrics ph·∫£i:
- port-forward Prometheus ho·∫∑c
- c√†i Grafana ri√™ng

**Kh√¥ng c√≥ Alertmanager:**

Kh√¥ng c√≥ c·∫£nh b√°o khi node/pod l·ªói

---

# Tri·ªÉn khai Ingress NGINX b·∫±ng Kustomize + Helm

## 1. C·∫•u tr√∫c file

### 1.1. kustomization.yaml

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: ingress-nginx

resources:
  - nginx-ingress-ns.yaml

helmCharts:
  - name: ingress-nginx
    repo: https://kubernetes.github.io/ingress-nginx
    version: 4.10.0
    releaseName: ingress-nginx
    namespace: ingress-nginx
    valuesFile: values.yaml
```

Gi·∫£i th√≠ch:
- Deploy Helm chart ingress-nginx version 4.10.0
- Namespace m·∫∑c ƒë·ªãnh: ingress-nginx
- File values.yaml ch·ª©a to√†n b·ªô c·∫•u h√¨nh custom
- nginx-ingress-ns.yaml d√πng ƒë·ªÉ t·∫°o namespace tr∆∞·ªõc

### 1.2. nginx-ingress-ns.yaml

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ingress-nginx
```

Ch·ª©c nƒÉng:
- T·∫°o namespace ri√™ng cho Ingress Controller
- Gi√∫p c√¥ l·∫≠p t√†i nguy√™n ingress v·ªõi workload kh√°c

## 2. C·∫•u h√¨nh controller (values.yaml)

### 2.1. Replica & IngressClass

```yaml
controller:
  replicaCount: 2
```

Ch·∫°y 2 pod ingress controller ƒë·ªÉ ƒë·∫£m b·∫£o HA c∆° b·∫£n.

```yaml
  ingressClassResource:
    enabled: true
    default: true
    name: nginx
```

- T·∫°o IngressClass t√™n nginx
- ƒê·∫∑t l√†m m·∫∑c ƒë·ªãnh cho to√†n cluster
- IngressClass d√πng ƒë·ªÉ x√°c ƒë·ªãnh Ingress resource s·∫Ω ƒë∆∞·ª£c x·ª≠ l√Ω b·ªüi controller n√†o.

#### V·∫•n ƒë·ªÅ n·∫øu kh√¥ng c√≥ IngressClass

Trong cluster c√≥ th·ªÉ c√≥ nhi·ªÅu Ingress Controller:
- nginx
- traefik
- istio
- haproxy

N·∫øu kh√¥ng c√≥ IngressClass:
‚Üí T·∫•t c·∫£ controller ƒë·ªÅu c√≥ th·ªÉ c·ªë x·ª≠ l√Ω c√πng m·ªôt Ingress
‚Üí xung ƒë·ªôt, route sai, l·ªói kh√≥ debug.

#### IngressClass ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o

B·∫°n khai b√°o m·ªôt IngressClass:

```yaml
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  name: nginx
spec:
  controller: k8s.io/ingress-nginx
```

Ingress Controller nginx s·∫Ω ch·ªâ qu·∫£n l√Ω c√°c Ingress c√≥:

```yaml
spec:
  ingressClassName: nginx
```

V√≠ d·ª•:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
spec:
  ingressClassName: nginx
  rules:
    - host: app.example.com
```

Ingress kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh ingressClassName v·∫´n d√πng nginx (n·∫øu ƒë·ªÉ default)

### 2.2. Ki·ªÉu workload

```yaml
  kind: Deployment
```

- Ch·∫°y controller d∆∞·ªõi d·∫°ng Deployment
- Ph√π h·ª£p autoscaling v√† rolling update

### 2.3. Service expose ra ngo√†i (NodePort)

```yaml
  service:
    enabled: true
    type: NodePort
    externalTrafficPolicy: Local
    ports:
      http: 80
      https: 443
    nodePorts:
      http: 30080
      https: 30443
```

Gi·∫£i th√≠ch:
- Expose HTTP qua port 30080
- Expose HTTPS qua port 30443
- `externalTrafficPolicy: Local`:
  - Gi·ªØ IP client th·∫≠t
  - Ch·ªâ route traffic t·ªõi node c√≥ pod ingress

Truy c·∫≠p t·ª´ ngo√†i:
- `http://NODE_IP:30080`
- `https://NODE_IP:30443`

### 2.4. Resource & Autoscaling

```yaml
  resources:
    requests:
      cpu: 200m
      memory: 256Mi
```

- ƒê·∫£m b·∫£o m·ªói pod c√≥ t√†i nguy√™n t·ªëi thi·ªÉu
- Tr√°nh b·ªã evict khi node thi·∫øu RAM

```yaml
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 60
```

- B·∫≠t HPA
- Scale t·ª´ 2 ‚Üí 5 pod
- Scale khi CPU > 60%

### 2.5. NGINX config (proxy & header)

(N·∫øu kh√¥ng c√≥ c·∫•u h√¨nh n√†y, NGINX s·∫Ω ch·ªâ th·∫•y IP c·ªßa proxy (v√≠ d·ª• node, LB), kh√¥ng ph·∫£i IP ng∆∞·ªùi d√πng th·∫≠t.)

**VD:** Client ‚Üí Proxy ‚Üí Ingress

Ingress ch·ªâ th·∫•y IP c·ªßa Proxy: üëâ 10.0.0.5

Ingress ƒë·ªçc header: `X-Forwarded-For: 1.2.3.4` ‚Üí bi·∫øt IP th·∫≠t c·ªßa ng∆∞·ªùi d√πng l√†: üëâ 1.2.3.4

"H√£y l·∫•y IP ng∆∞·ªùi d√πng t·ª´ header X-Forwarded-For do proxy g·ª≠i t·ªõi."

```yaml
  config:
    use-forwarded-headers: "true"
    proxy-real-ip-cidr: "0.0.0.0/0"
    real-ip-header: "X-Forwarded-For"
```

**CIDR** l√† c√°ch vi·∫øt g·ªçn m·ªôt d·∫£i IP b·∫±ng d·∫°ng IP/s·ªë-bit: `192.168.0.1/24` l√† 1 CIDR

- L·∫•y IP th·∫≠t c·ªßa client t·ª´ header
- `proxy-real-ip-cidr`: l√† cidr (d·∫£i ip) c·ªßa proxy m√† nginx tin ƒë·ªÉ l·∫•y forwarded client ip
- Ph√π h·ª£p khi c√≥ proxy ph√≠a tr∆∞·ªõc

```yaml
    proxy-body-size: "50m"
```

Cho ph√©p upload file t·ªëi ƒëa 50MB

```yaml
    proxy-read-timeout: "600"
    proxy-send-timeout: "600"
```

Timeout 10 ph√∫t cho request d√†i (upload, API ch·∫≠m)

```yaml
    worker-shutdown-timeout: "240s"
```

Cho ph√©p request ƒëang x·ª≠ l√Ω ho√†n th√†nh khi pod shutdown

```yaml
    enable-underscores-in-headers: "true"
```

Cho ph√©p header c√≥ d·∫•u _ (M·∫∑c ƒë·ªãnh NGINX kh√¥ng cho header c√≥ d·∫•u g·∫°ch d∆∞·ªõi _ v√¨ l√Ω do b·∫£o m·∫≠t v√† chu·∫©n HTTP.)

V√≠ d·ª• header b·ªã ch·∫∑n (SAU KHI B·∫¨T S·∫º ƒê∆Ø·ª¢C):
- `X_User_Id: 123`
- `auth_token: abc`

### 2.6. Security

```yaml
  allowSnippetAnnotations: false
```

Kh√¥ng cho d√πng annotation `nginx.ingress.kubernetes.io/server-snippet` ‚Üí ch√®n rule ƒë·ªôc h·∫°i

```yaml
nginx.ingress.kubernetes.io/server-snippet: |
  lua_package_path "/tmp/?.lua;;";
  access_by_lua_file /tmp/malicious.lua;
```

‚Üí H√£y cho ph√©p load file Lua t·ª´ th∆∞ m·ª•c /tmp. M·ªói request ƒëi v√†o server n√†y, h√£y ch·∫°y file /tmp/malicious.lua tr∆∞·ªõc khi x·ª≠ l√Ω ti·∫øp.

Client request ‚Üí Ingress NGINX ‚Üí ch·∫°y file malicious.lua ‚Üí r·ªìi m·ªõi forward t·ªõi app

### 2.7. Metrics & Prometheus

```yaml
  metrics:
    enabled: true
    service:
      enabled: true
    serviceMonitor:
      enabled: true
```

B·∫≠t endpoint metrics `/metrics`

Ingress s·∫Ω m·ªü URL: `/metrics`

T·∫°i ƒë√¢y c√≥ s·ªë li·ªáu nh∆∞:
- s·ªë request
- response time
- status code (200, 404, 500‚Ä¶)
- s·ªë connection
- l·ªói 4xx, 5xx

T·∫°o ServiceMonitor ƒë·ªÉ Prometheus scrape t·ª± ƒë·ªông

Ph√π h·ª£p v·ªõi kube-prometheus-stack

### 2.8. PodDisruptionBudget

```yaml
  podDisruptionBudget:
    enabled: true
    minAvailable: 1
```

- Lu√¥n gi·ªØ √≠t nh·∫•t 1 pod ingress ho·∫°t ƒë·ªông
- Tr√°nh downtime khi node drain / upgrade

### 2.9. Affinity (ch·ªëng d·ªìn pod 1 node)
~
```yaml
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            topologyKey: kubernetes.io/hostname
```

- Tr√°nh schedule 2 ingress pod tr√™n c√πng node
- TƒÉng t√≠nh s·∫µn s√†ng

### 2.10. Graceful shutdown

```yaml
  terminationGracePeriodSeconds: 300
```

Cho pod 5 ph√∫t ƒë·ªÉ x·ª≠ l√Ω request tr∆∞·ªõc khi kill

```yaml
  lifecycle:
    preStop:
      exec:
        command:
          - /wait-shutdown
```

Script ch·ªù nginx x·ª≠ l√Ω xong connection

## 3. Default Backend

```yaml
defaultBackend:
  enabled: true
```

- T·∫°o service backend m·∫∑c ƒë·ªãnh
- Tr·∫£ v·ªÅ 404 khi request kh√¥ng match ingress rule

## 4. C√°ch tri·ªÉn khai

```bash
kustomize build --enable-helm . | kubectl apply -f -
```

Ho·∫∑c v·ªõi ArgoCD:
- Application tr·ªè t·ªõi th∆∞ m·ª•c ch·ª©a kustomization.yaml
- ArgoCD render Helm chart v√† sync v√†o cluster

## 5. Khi n√†o n√™n d√πng c·∫•u h√¨nh n√†y

Ph√π h·ª£p:
- Cluster on-premise / k3s / lab
- Mu·ªën autoscaling ingress
- C√≥ Prometheus scrape metrics